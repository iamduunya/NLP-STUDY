{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PQSnsGeA2OH"
      },
      "source": [
        "# 트랜스포머 (Transformer)\n",
        "\n",
        "* 참고: https://wikidocs.net/31379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbQ-h_XxBAiq"
      },
      "source": [
        "* attention mechanism은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n",
        "* attention mechanism을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n",
        "* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDiFPIdUBBS2"
      },
      "source": [
        "## 포지셔널 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqHf_4SEWoa"
      },
      "source": [
        "* 기존의 RNN은 단어의 위치를 따라 순차적으로 입력받아 단어의 위치정보를 활용할 수 있었음\n",
        "* 트랜스포머의 경우, RNN을 활용하지 않았기 때문에 단어의 위치정보를 다른 방식으로 줄 필요가 있음\n",
        "* 이를 위해 **각 단어의 임베딩 벡터에 위치 정보들을 더하게 되는데** 이를 포지셔널 인코딩이라 함\n",
        "* 보통 포지셔널 인코딩은 sin, cos을 이용하여 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiO5c_HIFBAk"
      },
      "source": [
        "def positional_encoding(dim, sentence_length):\n",
        "  encoded_vec=np.array([pos/np.power(10000,2*i/dim)for pos in range(sentence_length) for i in range(dim)])\n",
        "  encoded_vec[::2]=np.sin(encoded_vec[::2]) # 짝수는 sin\n",
        "  encoded_vec[::2]=np.cos(encoded_vec[1::2]) # 홀수는 cos\n",
        "  return tf.constant(encoded_vec.reshape([sentence_length,dim]),dtype=tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099gUUxhAgy3"
      },
      "source": [
        "## 레이어 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdips98yPuH"
      },
      "source": [
        "*  레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화함\n",
        "*  해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJjxF86Aeg3"
      },
      "source": [
        "# 레이어 정규화\n",
        "def layer_norm(inputs,eps=1e-6):\n",
        "  feature_shape=inputs.get_shape()[-1:]\n",
        "  mean=tf.keras.backed.mean(inputs,[-1],keepims=True)\n",
        "  std=tf.keras.backed.std(inputs,[-1],keepims=True)\n",
        "  beta=tf.Variable(tf.zeros(feature_shape),trainable=False)\n",
        "  gamma=tf.Variable(tf.ones(feature_shape),trainable=False)\n",
        "  return gamma*(inputs-mean)/(std+eps)+beta\n",
        "# feature_shape이 유지된 채로 레이어 정규화 가능"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km9ORxIun-MU"
      },
      "source": [
        "def sublayer_connection(inputs, sublayer, dropout=0.2):\n",
        "  outputs=layer_norm(input+tf.keras.layers.Dropout(dropout)(sublayer))\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppb7IxJ3diMC"
      },
      "source": [
        "## 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaU6MHgy9V2"
      },
      "source": [
        "\n",
        "\n",
        "*   트랜스포머 모델의 핵심이 되는 부분\n",
        "*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n",
        "  1.   multi-head attention\n",
        "      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n",
        "      *  마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n",
        "      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n",
        "  2.   self attention\n",
        "      *   일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n",
        "      *   이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n",
        "      *   반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n",
        "      *   이는 입력 문장 내 단어간의 어텐션을 의미함\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRyL0KDXi6ej"
      },
      "source": [
        "### scaled-dot product attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HtmcgRR3Cr-"
      },
      "source": [
        "* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n",
        "* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n",
        "* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALEMzi4fdiSQ"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, masked=False):\n",
        "  key_dim_size=float(key.get_shape().as_list()[-1])\n",
        "  key=tf.transpose(key,perm[0,2,1])\n",
        "\n",
        "  outputs=tf.matmul(query,key)/tf.sqrt(key_dim_size)\n",
        "\n",
        "  if masked:\n",
        "    diag_vals=tf.ones_like(outputs[0,:,:])\n",
        "    tril=tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()\n",
        "    masks=tf.tile(tf.expand_dims(tril,0),[tf.shae(outputs)[0],1,1])\n",
        "    paddings=tf.ones_like(masks)*(-2**30)\n",
        "    outputs=tf.where(tf.equa(masks,0),paddings,outputs)\n",
        "\n",
        "  attention_map=tf.nn.softmax(outputs)\n",
        "  return tf.matunl(attention_map,value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr20BxvVi-8b"
      },
      "source": [
        "### multi-head attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb5qflUH14-H"
      },
      "source": [
        "* multi-head attention의 구현 과정\n",
        "  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n",
        "  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n",
        "  3. 분리한 행렬들에 대해 각각 어텐션을 수행\n",
        "  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooc3FAdQi_Gz"
      },
      "source": [
        "def multi_head_attention(query,key,value,num_units,heads,masked=False):\n",
        "  query=tf.keras.layers.Dense(num_units,activation=tf.nn.relu)(query)\n",
        "  key=tf.keras.layers.Dense(num_units,activation=tf.nn.relu)(key)\n",
        "  value=tf.keras.layers.Dense(num_units,activation=tf.nn.relu)(value)\n",
        "\n",
        "  query=tf.concat(tf.split(query,heads,axis=-1),axis=0)\n",
        "  key=tf.concat(tf.split(query,heads,axis=-1),axis=0)\n",
        "  value=tf.concat(tf.split(query,heads,axis=-1),axis=0)\n",
        "\n",
        "  attention_map=scaled_dot_product_attention(query,key,value,masked)\n",
        "  attn_outputs=tf.concat(tf.split(attention_map,heads,axis=0),axis=-1)\n",
        "  attn_outputstf.keras.layers.Dense(num_units,activation=tf.nn.relu)(attn_outputs)\n",
        "\n",
        "  return attn_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Zn5-fYITD4"
      },
      "source": [
        "## 포지션-와이즈 피드 포워드 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxeG2xvo3ZN"
      },
      "source": [
        "\n",
        "\n",
        "*   multi-head attention의 결과인 행렬을 입력받아 연산\n",
        "*   일반적인 완전 연결 신경망(Dense layer)를 사용\n",
        "*   position-wise FFNN은 인코더와 디코더에 모두 존재\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tSFd5OaITJ0"
      },
      "source": [
        "def feed_forward(inputs, num_units):\n",
        "  feature_shape=inputs.get_shape()[-1]\n",
        "  inner_layer=tf.keras.layers.Dense(num_units,activation=tf.nn.relu)(inputs)\n",
        "  outputs=tf.keras.layers.Dense(feature_shape)(inner_layer)\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuccViYgBK6v"
      },
      "source": [
        "## 인코더\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG3MH0n1JVLz"
      },
      "source": [
        "* 인코더는 하나의 어텐션을 사용\n",
        "  + encoder self-attention (multi-head self-attention과 동일)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5T0pzBoAnn3"
      },
      "source": [
        "def encoder_module(inputs, model_dim, ffn_dim, heads):\n",
        "  self_attn=sublayer_connection(inputs, multi_head_attention(inputs, inputs,inputs,model_dim,heads))\n",
        "  # inputs과 multi_head_attention을 sublayer_connection해줌(정규화하고 0.2 dropout)\n",
        "  outputs=sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
        "  return outputs\n",
        "\n",
        "def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n",
        "  outputs=inputs\n",
        "  for i in range(num_layers):\n",
        "    outputs=encoder_module(outputs, model_dim,ffn_dim,heads)\n",
        "\n",
        "  return outputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcgHRcTEBQqg"
      },
      "source": [
        "## 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNj-6FLQwT4-"
      },
      "source": [
        "* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n",
        "  1. masked decoder self-attention\n",
        "  2. encoder-decoder attention\n",
        "  3. position-wise FFNN\n",
        "\n",
        "* 디코더에서는 2종류의 어텐션을 사용\n",
        "  1.   masked decoder self-attention\n",
        "    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n",
        "    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n",
        "    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n",
        "  2.   encoder-decoder attention\n",
        "    *   앞서 설명한 multi-head attention과 동일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B05wr7aARcT"
      },
      "source": [
        "def decoder_module(inputs,encoder_outputs, model_dim, ffn_dim,heads):\n",
        "  masked_self_attn=sublayer_connection(inputs,multi_head_attention(inputs,inputs,inputs,\n",
        "                                                                   model_dim, heads, masked=True))\n",
        "  self_attn=sublayer_connection(masked_self_attn,\n",
        "                                multi_head_attention(masked_self_attn,\n",
        "                                                     encoder_outputs,\n",
        "                                                     encoder_outputs,\n",
        "                                                     model_dim,heads))\n",
        "  outputs=sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
        "  return outputs\n",
        "\n",
        "def decoder(inputs,encoder_outputs, model_dim, ffn_dim,heads,num_layers):\n",
        "  outputs=inputs\n",
        "  for i in range(num_layers):\n",
        "    outputs=decoder_module(outputs, encoder_outputs, model_dim, ffn_dim, heads)\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtztlyUB1ERS"
      },
      "source": [
        "## 트랜스포머를 활용한 챗봇"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CGUIAzv6eWs"
      },
      "source": [
        "### konlpy 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae0mHT49v5gy"
      },
      "source": [
        "*    한글을 처리하기 위해 konlpy 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yf75uG6hBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d109be4-f5bd-4fd0-ebfa-bd6f783c1399"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUMXvK5H1G9H"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miXrjR316mNb"
      },
      "source": [
        "* 처리에 필요한 각종 변수 선언\n",
        "* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMjn5PfE1GZR"
      },
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "filters=\"([~.,!?\\\"':;)()])\"\n",
        "PAD='<PADDING'\n",
        "STD='<START'\n",
        "END='<END'\n",
        "UNK='<UNKNOWN>'\n",
        "\n",
        "PAD_INDEX=0\n",
        "STD_INDEX=1\n",
        "END_INDEX=2\n",
        "UNK_INDEX=3\n",
        "\n",
        "MARKER=[PAD,STD,END,UNK]\n",
        "CHANGE_FILTER=re.compile(filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmRFuH2r6oNJ"
      },
      "source": [
        "* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrmdXkePWYb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data(data_path):\n",
        "  data_df=pd.read_csv(data_path, header=0)\n",
        "  question, answer=list(data_df['0']), list(data_df['A'])\n",
        "  train_input, eval_input, train_label, eval_label=train_test_split(question,\n",
        "                                                                    answer,\n",
        "                                                                    test_size=0.33,\n",
        "                                                                    random_state=111)\n",
        "  return train_input, eval_input, train_label, eval_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHuOJHPtPXqq"
      },
      "source": [
        "* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQL-AP06oSa"
      },
      "source": [
        "def load_vocabulary(data_path):\n",
        "   data_df=pd.read_csv(data_path, encoding='utf-8')\n",
        "   question, answer=list(data_df['0']), list(data_df['A'])\n",
        "\n",
        "   if tokenize_as_morph:\n",
        "    question=prepro_like_morphlized(question)\n",
        "    answer=prepro_like_morphlized(answer)\n",
        "\n",
        "    data=[]\n",
        "    data.extend(question)\n",
        "    data.extend(answer)\n",
        "    words=data_tokenizer(data)\n",
        "    words=list(set(words))\n",
        "    words[:0]=MARKER\n",
        "\n",
        "    char2idx={char:idx for idx, char in enumerate(words)}\n",
        "    idx2char={idx:char for idx, char in enumerate(words)}\n",
        "    return char2idx, idx2char, len(char2idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wYtpjv76r5q"
      },
      "source": [
        "* 문자열 데이터를 학습에 사용될 수 있도록 변현하는 `prepro_like_morphlized()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQ3FOva6tg6"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "def prepro_like_morphlized(data):\n",
        "  morph_analyzer=Okt()\n",
        "  result_data=list()\n",
        "  for seq in data:\n",
        "    morphlized_sed=\" \".join(morph_analyzer.morphs(seq.replace(' ','')))\n",
        "    result_data.append(morphlized_seq)\n",
        "  return result_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhsVp4pWPTR3"
      },
      "source": [
        "* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otLI_RUfPR_g"
      },
      "source": [
        "def data_tokenizer(data):\n",
        "  words=[]\n",
        "  for sentence in data:\n",
        "    sentence=re.sub(CHANGE_FILTER,'',sentence)\n",
        "    for word in sentence.split():\n",
        "      words.append(word)\n",
        "    return [word for word in words if word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkKPA-Mx6uaC"
      },
      "source": [
        "* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-yeSThPGsa"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def enc_processing(value, dictionary):\n",
        "  sequences_input_index=[]\n",
        "  sequences_length=[]\n",
        "\n",
        "  if tokenize_as_morph:\n",
        "    value=prepro_like_morphlized(value)\n",
        "\n",
        "    for sequence in value:\n",
        "      sequence = re.sub(CHANGE_FILTER,'',sequence)\n",
        "      sequence_index=[]\n",
        "      for word in sequence.split():\n",
        "        if dictionary.get(word) is not None:\n",
        "          sequence_index.extend([dictionary[word]])\n",
        "        else:\n",
        "          sequence_index.extend([dictionary[UNK]])\n",
        "        if len(sequence_index)>max_len:\n",
        "          sequences_length=sequence_index[:max_len]\n",
        "        sequences_length.append(len(sequence_index))\n",
        "        sequence_index+=(max_len-len(sequence_index))*[dictionary[PAD]]\n",
        "        sequences_input_index.append(sequence_index)\n",
        "      return np.array(sequences_input_index), sequences_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mM57_FPIg7"
      },
      "source": [
        "* decoder의 입력을 구성하기 위한 함수 `dec_input_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_NpcTq6vw6"
      },
      "source": [
        "def dec_output_processing(value, dictionary):\n",
        "  sequences_output_index=[]\n",
        "  sequences_length=[]\n",
        "\n",
        "  if tokenize_as_morph:\n",
        "    value=prepro_like_morphlized(value)\n",
        "\n",
        "    for sequence in value:\n",
        "      sequence = re.sub(CHANGE_FILTER,'',sequence)\n",
        "      sequence_index=[]\n",
        "      sequence_index=[dictionary[STD]+[dictionary[word] for word in sequence.split()]]\n",
        "      if len(sequence_index)>max_len:\n",
        "          sequences_length=sequence_index[:max_len]\n",
        "          sequences_length.append(len(sequence_index))\n",
        "          sequence_index+=(max_len-len(sequence_index))*[dictionary[PAD]]\n",
        "          sequences_output_index.append(sequence_index)\n",
        "      return np.array(sequences_output_index), sequences_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otsTEt4FPLJX"
      },
      "source": [
        "* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeP0PWHEPMma"
      },
      "source": [
        "def dec_target_processing(value, dictionary):\n",
        "  sequences_target_index=[]\n",
        "\n",
        "  if tokenize_as_morph:\n",
        "    value=prepro_like_morphlized(value)\n",
        "\n",
        "    for sequence in value:\n",
        "      sequence = re.sub(CHANGE_FILTER,'',sequence)\n",
        "      sequence_index=[[dictionary[word] for word in sequence.split()]]\n",
        "      if len(sequence_index)>=max_len:\n",
        "          sequences_length=sequence_index[:max_len-1]+[dictionary[END]]\n",
        "      else:\n",
        "        sequences_length+=[dictionary[END]]\n",
        "      sequence_index+=(max_len-len(sequence_index))*[dictionary[PAD]]\n",
        "      sequences_target_index.append(sequence_index)\n",
        "      return np.array(sequences_target_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9vVUng6xDq"
      },
      "source": [
        "* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n",
        "* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n",
        "* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlKV4xF62Uf"
      },
      "source": [
        "def train_input_fn(train_input_enc, train_output_enc, train_traget_dec, batch_size):\n",
        "  dataset=tf.compat.v1.data.Dataset.from_tensor_slices(train_input_enc, train_output_enc, train_target_dec)\n",
        "  dataset=dataset.shuffle(buffer_size=len(train_input_enc))\n",
        "  dataset=dataset.batch(batch_size)\n",
        "  dataset=dataset.map(rearrange)\n",
        "  dataset=dataset.repeat()\n",
        "  iterator=dataset.make_one_shot_iterator()\n",
        "  return iterator.get_next()\n",
        "\n",
        "def eval_input_fn(eval_input_enc, eval_output_enc,eval_traget_dec, batch_size):\n",
        "  dataset=tf.compat.v1.data.Dataset.from_tensor_slices(eval_input_enc, eval_output_enc, eval_traget_dec)\n",
        "  dataset=dataset.shuffle(buffer_size=len(eval_input_enc))\n",
        "  dataset=dataset.batch(batch_size)\n",
        "  dataset=dataset.map(rearrange)\n",
        "  dataset=dataset.repeat()\n",
        "  iterator=dataset.make_one_shot_iterator()\n",
        "  return iterator.get_next()\n",
        "\n",
        "def rearrange(input, output, target):\n",
        "  features={'input':input,'output':output}\n",
        "  return features, target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is-GhUDN62xC"
      },
      "source": [
        "* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n",
        "* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfwWXhb64Cc"
      },
      "source": [
        "def pre2string(value, dictionary):\n",
        "  sentence_string=[]\n",
        "  is_finished=False\n",
        "  for v in value:\n",
        "    sentence_string=[dictionary[index]for index in v['indexs']]\n",
        "  answer=''\n",
        "  for word in sentence_string:\n",
        "    if word==END:\n",
        "      if_finished=True\n",
        "      break\n",
        "    if word!=PAD and word!=END:\n",
        "      answer+=word\n",
        "      answer+=''\n",
        "    return answer, is_finished"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwp9Nnwz7UoG"
      },
      "source": [
        "* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\n",
        "* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T536MdU7Taq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a7fc2f3f-c927-4c3d-c58b-38038ce245b3"
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
        "train_data = pd.read_csv('ChatBotData.csv')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49de411d-d1fc-418f-b683-e182e1241981\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49de411d-d1fc-418f-b683-e182e1241981')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49de411d-d1fc-418f-b683-e182e1241981 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49de411d-d1fc-418f-b683-e182e1241981');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-843a1f7e-7b79-4a12-825f-3ff2e559adae\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-843a1f7e-7b79-4a12-825f-3ff2e559adae')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-843a1f7e-7b79-4a12-825f-3ff2e559adae button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data",
              "summary": "{\n  \"name\": \"train_data\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cVd7AOKinqn"
      },
      "source": [
        "### 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqLJ0a6r49yi"
      },
      "source": [
        "* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNeeXoZginvj"
      },
      "source": [
        "def build_model(features, labels, mode, params):\n",
        "  TRAIN=mode==tf.estimator.ModeKeys.TRAIN\n",
        "  EVAL=mode==tf.estimator.ModeKeys.EVAL\n",
        "  PREDICT=mode==tf.estimator.ModeKeys.PREDICT\n",
        "\n",
        "  position_encode=positional_encoding(params['embedding_size'], params['max_len'])\n",
        "  if params['xavier_initializer']:\n",
        "    embedding_initializer='glorot_normal'\n",
        "  else:\n",
        "    embedding_initializer='iniform'\n",
        "\n",
        "  embedding=tf.keras.layers.Embedding(params['len_vocab'],\n",
        "                                      params['embedding_size'],\n",
        "                                      embedding_initializer=embedding_initializer)\n",
        "\n",
        "  x_embedded_matrix=embedding(features['input'])+position_encode\n",
        "  y_embedded_matrix=embedding(features['output'])+position_encode\n",
        "\n",
        "  encoder_outputs=encoder(x_embedded_matrix,params['model_hidden_size'],\n",
        "                          params['ffn_hidden_size'],\n",
        "                          params['attention_head_size'],\n",
        "                          params['layer_size'])\n",
        "  decoder_outputs=decoder(y_embedded_matrix,encoder_outputs,params['model_hidden_size'],\n",
        "                          params['ffn_hidden_size'],\n",
        "                          params['attention_head_size'],\n",
        "                          params['layer_size'])\n",
        "\n",
        "  logits=tf.keras.layers.Dense(params['len_vocab'])(decoder_outputs)\n",
        "  predict=tf.argmax(logits,2)\n",
        "\n",
        "  if PREDICT:\n",
        "    predictions={'indexs':predict,\n",
        "                 'logits':logits}\n",
        "    return tf.estimator.EstimatorSpec(mode,predictions=predictions)\n",
        "\n",
        "  labels_=tf.one_hot(labels,params['len_vocab'])\n",
        "  loss=tf.reduce_mean(tf.compat.v1.nn.sotfmax_cross_entropy_with_logots_v2(logits=logits, labels=labels))\n",
        "  accuracy=tf.compat.v1.metrics.accuracy(labels=labels,predictions=predict)\n",
        "\n",
        "  matrics={'accuracy':accuracy}\n",
        "  tf.summary.scalar('accuracy',accuracy[1])\n",
        "\n",
        "  if EVAL:\n",
        "    return tf.estimator.EstimatorSpec(mode,loss=loss, eval_metrics_ops=metrics)\n",
        "  assert TRAIN\n",
        "\n",
        "  optimizer=tf.compat.v1.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "  train_op=optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())\n",
        "  return tf.estimator.EstimatiorSpec(mode, loss=loss, train_op=train_op)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7PrLEWE1JCs"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy_Opm_A7DKC"
      },
      "source": [
        "*   필요한 각종 인자들을 설정\n",
        "*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGYuqmH6_kj"
      },
      "source": [
        "max_len=25\n",
        "epoch=5000\n",
        "batch_size=256\n",
        "embedding_size=100\n",
        "model_hidden_size=100\n",
        "ffn_hidden_size=100\n",
        "attention_head_size=100\n",
        "lr=0.001\n",
        "layer_size=3\n",
        "xavier_initializer=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaXalEy57ODq"
      },
      "source": [
        "*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n",
        "*   평가 데이터에도 동일하게 가공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlgWWIq1KSh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ab9972ec-c50d-43fb-c373-a550dcc738c4"
      },
      "source": [
        "train_input_enc, train_input_enc_length=enc_processing(train_input, char2idx)\n",
        "train_output_dec, train_output_dec_length=dec_output_processing(train_label,char2idx)\n",
        "train_target_dec=dec_target_processing(train_label,char2idx)\n",
        "\n",
        "eval_input_enc, eval_input_enc_length=enc_processing(eval_input, char2idx)\n",
        "eval_output_dec, eval_output_dec_length=dec_output_processing(eval_label,char2idx)\n",
        "eval_target_dec=dec_target_processing(eval_label,char2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-827b41a2e2d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_enc_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_output_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output_dec_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_output_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_target_dec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdec_target_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meval_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_input_enc_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZGgZzWs7Mr7"
      },
      "source": [
        "* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n",
        "* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9vjc3Ck7F4J"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl_pwUiw7INZ"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COO-0PcS7Hy5"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNcrVf2z1LSM"
      },
      "source": [
        "### 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5lY9DrW8eSK"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9IQaBx4Qw8J"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjHZKvJ31MAU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mjRZwyLQ_gP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7AJCsXRTqJx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M8mfoUfeAWQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5mrdGRaem6v"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}